{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Z6Wtb_jisbA"
   },
   "source": [
    "# Reuters database: multiclass classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellView": "form",
    "id": "QUyRGn9riopB"
   },
   "source": [
    "## 보도자료 분류 : 46개 서로 다른 토픽으로 분류되는 로이터 보도자료 데이터베이스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1yCdGFW4j_F"
   },
   "source": [
    "- 만약 각각의 데이터들이 하나의 카테고리에 해당하면 single-label, multiclass classification\n",
    "- 만약 각각의 데이터들이 복수의 카테고리에 해당 (이 경우, topic)하면, multilabel, multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PS6_yKSoyLAl"
   },
   "source": [
    "### Reuters 데이터세트 로드 \n",
    "- Reuters 데이터세트는 Keras 에 패키지 되어 같이 제공됨\n",
    "- 46개 토픽당 최소 10개 이상의 example 이 제공됨\n",
    "- num_words=10000 은 10,000개의 제일 많이 발생하는 단어로 제한을 둠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
    "    num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4YZ_ievcY7p"
   },
   "source": [
    "- 8,982 개 train 데이터와 2,246 test 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IFct0yedsTy"
   },
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train 데이터는 word indeces 의 정수 리스트들고 이루어져 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPo5bQwndr9P"
   },
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5w4m5gncnGh"
   },
   "source": [
    "#### 인코딩 되어있는 보도자료 데이터를 디코딩\n",
    "- word_index 는 단어를 정수 인덱스로 dictionary 형태로 mapping\n",
    "- reverse_word_index 를 통해 index 를 단어로 mapping\n",
    "- decode_review 에서 3개의 index 들은 시스템 내부에서 예약되어 있음: 0: \"padding\", 1: \"start of sequence\", 2: \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSyrXp_He_UE"
   },
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_newswire = \" \".join([reverse_word_index.get(i - 3, \"?\") for i in\n",
    "    train_data[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6mTfIQzfC9w"
   },
   "source": [
    "- 아래 예에 해당하는 레이블은 토픽 인덱스 (0~45 까지의) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PumyCN8VdGGc"
   },
   "outputs": [],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHFxNLszhQjz"
   },
   "source": [
    "### 데이터 준비\n",
    "#### input data 를 인코딩\n",
    "- 리스틀 tensor 로 신경망에 주입\n",
    "- 정수 리스트를 0 과 1 로 이루어진 one-hot vector 로 변환하여 인코딩\n",
    "- 맨처음 results 를 0 으로 채워진 행렬을 생성\n",
    "- \"results[i, sequence] = 1\" 를 통하여 특정 index 의 results 를 1 로 셋팅\n",
    "- train 과 test 데이터를 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOJt-ML4hAwI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQJEYfVvfznP"
   },
   "source": [
    "#### 레이블을 인코딩\n",
    "- 레이블의 범위 0 ~ 45 (topics) 이므로 dimension=46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zM0wz2TueuA6"
   },
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZx1L_1Vcmxv"
   },
   "source": [
    "- Keras 에 내장된 방법을 통해서도 one_hot_vector 를 만들 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2OcguDfBcmmg"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzr5vRr5caGF"
   },
   "source": [
    "- 이제 데이터는 신경망에 투입될 수 있게 준비 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpXvGjfnjHgY"
   },
   "source": [
    "### 모델 구축\n",
    "- 보도자료 문서를 분류하여 46개의 토픽 중 어디에 해당하는지를 분류하는 문제\n",
    "- 출력층은 46 차원의 class 를 다루어야 함\n",
    "- 64 차원의 Dense 층을 relu 활성화 함수로 갖춘 2개의 stack 를 거쳐 마지막 층에 46 차원의 Dense 층에 softmax 활성화 함수로\n",
    "- 46개 class 가 확률분포를 각각 갖게되고 결국 총 합은 1 이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T20u1anCi8NP"
   },
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIwcFT4MlZEi"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTTriO8FlSML"
   },
   "source": [
    "### 모델 컴파일\n",
    "- 이 문제와 같은 categorical classification 문제에는 categorical_crossentropy loss 가 가장 좋은 선택\n",
    "- 모델의 확률분포 출력과 레이블의 실제 분포 사이의 거리를 측정\n",
    "- rmsprop 옵티마이저는 거의 모든 문제에 있어 좋은 default 선택\n",
    "- accuracy 를 선언하여 훈련 동안 정확도를 모니터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpKkhMoZljco"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuE59XHEl22K"
   },
   "source": [
    "## 모델 성능 검증\n",
    "- train 데이터 중에 10000 개를 validate 용으로 별도 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnf4o2V5lcPn"
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzzt5nUpmEe3"
   },
   "source": [
    "## 모델 Training\n",
    "- 훈련을 20회 반복하면서 실행 (epoch)\n",
    "- mini-batch 크기는 512 샘플\n",
    "- 검증용으로 분할 했던 10000 개 샘플(x_val, y_val)에 대하여 정확도와 손실을 모니터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnihuLdWmE75"
   },
   "outputs": [],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNvJLH8hmsdf"
   },
   "source": [
    "### Training 과 Validation loss 를 matplotlib 를 사용하여 plot\n",
    "\n",
    "- 'bo' 는 blue dot 을 의미\n",
    "- 'b'는 solid blue line 을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A169XuO4mKxF"
   },
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnPMP5EHph17"
   },
   "source": [
    "### Training 과 Validation accuracy\n",
    "- plt.clf 는 clear the picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur624ibpp52X"
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wltc0jpgng38"
   },
   "source": [
    "- training accuracy 는 지속적으로 증가하는 데 반해, validation accuracy 는 9 epoch 이후에 증가세가 멈춤\n",
    "- 전형적인 overfitting 문제. 문제를 방지하기 위해 모델을 새롭게 9 epoch 까지만 정의하고 훈련 시행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsETKQo0rHvi"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "  layers.Dense(64, activation=\"relu\"),\n",
    "  layers.Dense(64, activation=\"relu\"),\n",
    "  layers.Dense(46, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Efm4mLzkrCxp"
   },
   "source": [
    "- 마지막 results 는 아래와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  80% 에 근접한 정확도를 보임\n",
    "-  임의로 분류를 시행하면 몇 % 정확도를 보일까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
    "float(np.sum(hits_array)) / len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- random classifier 는 19% 의 분류 정확도를 보이는 것을 감안할 때, 이번 결과는 상당히 좋은 것으로 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트 데이터를 통하여 topic 을 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prediction 의 각각의 entry 들은 46 길이의 벡터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 46 클래스의 확률분포를 나타내므로 전체 합은 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가장 높은 확률을 가진 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- one-hot-encoding 말고 다른 방법으로 labels 와 loss 를 다루는 방법\n",
    "- 레이블을 정수 텐서로 인코딩 하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 경우 유일하게 바뀌는 부분은 loss 함수의 선택\n",
    "- 정수 레이블의 경우, sparse_categorical_crossentropy 를 사용해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 충분히 큰 중간 층(layer) 의 중요성\n",
    "- 최종 output 이 46 차원이어서 중간 층이 46 unit 보다 적은 경우를 피해야 한다고 설명하였는데\n",
    "- 만약 46 보다 작은 예를 들어 4 unit 을 사용한다면 어떻게 될까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델은 71% validation accuracy 에서 정점을 찍고 8% 하강한다. \n",
    "- 이런 현상은 주로 너무 작은 차원의 중간 공간을 가지고 많은 정보를 압축하려고 시도 하는 것에 기인한다.\n",
    "- 4차원의 작은 공간에 대부분의 많은 정보를 꾸겨넣으려고 하지만 모두 담을 수는 없는 것이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "premade.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
